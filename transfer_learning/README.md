**（1）简介**  
>这一部分主要是测试自定义数据集和迁移学习的使用。    
**utils.py**中包含两部分内容：   
一是Config类，用于设置模型中用到的超参数。   
二是数据集的定义。本次实验过程中使用的数据集是pokemon(宝可梦)数据集，与utils.py、model.py和main.py三个文件在同一目录下。      
pokemon数据集中有5个文件夹，里面分别包含5个精灵的图片。   
在utils.py中根据精灵的类别对5个精灵编码，将每张精灵图片的路径和对应的类别编码写入csv文件夹，一张一行。   
需要调用数据集时，先检查csv文件是否存在，如果不存在，则先创建，然后读取，如果存在，直接读取，然后根据mode(train/val/test)得到相应的图片路径和类别编码，最后再进行预处理，便可以得到图片形式的image和one-hot形式的类别编码。   
**model.py**中包含了模型的定义：   
考虑到pokemon数据集较小，直接训练经典的网络如VGG，ResNet等会导致过拟合，此处使用了迁移学习方法。   
先使用keras框架加载在imagenet大型数据集上预训练好的VGG19，去掉最后一个网络层，并设置网络参数不可训练，然后将这个预训练模型加入到本次实验用到的网络中，最后再添加几个自定义网络层，即可得到需要的模型。   
**main.py**是先加载数据集和模型，然后使用keras框架对模型进行训练和测试。   

**(2)遇到的坑**   
>训练过程中，loss变为nan,accuracy却在上升。   
loss变为nan，通常情况下，要么是模型有问题，要么是学习率过大，或者是数据有问题。     
首先根据在utils.py中的测试，数据基本没有什么问题。   
于是，我先试着调小学习率，但是发现这种情况仍然存在，便检查模型的定义。   
最后发现，网络最后一层的激活函数设置成了sigmoid，把它调整为softmax，再训练、测试，一切正常。
